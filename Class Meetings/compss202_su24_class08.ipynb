{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4943e00-491f-41d4-af95-91fd1238f12d",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ryanedw/COMPSS-202-SU24/main/Images/UCB-macss.jpg\" width=\"120\" align=\"right\"/>\n",
    "<h1>COMPSS 202 Class 08</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cfe46-7f35-4fcf-88ba-49f79a894527",
   "metadata": {},
   "source": [
    "<h2>Errors in Regression</h2>\n",
    "\n",
    "Inspired by [SticiGui Chapter 11](https://www.stat.berkeley.edu/~stark/SticiGui/Text/regressionErrors.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77f72c-9bf6-4808-856d-7779e492179a",
   "metadata": {},
   "source": [
    "<h3>Learning objectives:</h3>\n",
    "\n",
    "<ol style=\"margin-top: 0; margin-bottom: 0;\">\n",
    "  <li>More about regression\n",
    "   <ul style=\"margin-top: 0; margin-bottom: 0;\">\n",
    "      <li>Etymology: regression is the opposite of progression\n",
    "      </li>\n",
    "      <li>A regression model yields a great prediction of $Y$ given $X$, but the prediction is hardwired to show regression to the mean\n",
    "      </li>\n",
    "      <li>The regression fallacy is to ignore this hardwiring and instead attribute regression to the mean to a “jinx” or a third variable like praise or criticism\n",
    "      </li>\n",
    "   </ul>\n",
    "  </li>\n",
    "      <li>Residuals, sum of squared errors, $R^2 = r \\times r$, and overall regression “fit”\n",
    "   <ul style=\"margin-top: 0; margin-bottom: 0;\">\n",
    "      <li>(This is not the same as statistical significance, which we’re building up to)\n",
    "      </li>\n",
    "    </ul>\n",
    "   </li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66ba97-e239-451a-b4cd-60a2606a04b9",
   "metadata": {},
   "source": [
    "To begin, please run the cells below to load up the libraries necessary to access data in Google Sheets. Best practices include running the cells in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635104b1-d28e-480d-aadf-42c62360f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"googlesheets4\")\n",
    "library(googlesheets4)\n",
    "gs4_deauth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0097a45-8cc5-42a7-987a-6fb0c34321e5",
   "metadata": {},
   "source": [
    "<h2>1. Review of earlier results with the Pearson heights data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccedfdd-5a84-4314-a8d5-9a43043a6bda",
   "metadata": {},
   "source": [
    "Here again are 1,078 observations of \"fathers\" and \"sons\" from a well-known training dataset based on the historical work of [Karl Pearson](https://en.wikipedia.org/wiki/Karl_Pearson). Please see the Class 03 notebook for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5429b-3119-4bc7-81f2-22f113bcfc61",
   "metadata": {},
   "source": [
    "Here is a direct link to the Google Sheets file loaded in the cell below: [Pearson height data.sheets](https://docs.google.com/spreadsheets/d/1TZhFGjT-uXd9ScucSYkT0MNARNDMCRCbAQgx4jac-X8/edit?usp=drive_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881dd2a-c149-45ab-8cb2-268fc983548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1TZhFGjT-uXd9ScucSYkT0MNARNDMCRCbAQgx4jac-X8/edit?usp=drive_link\"\n",
    "\n",
    "pheights <- read_sheet(sheet_url,\n",
    "                       range = \"B13:D1091\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344247a-9db0-48b0-8f00-d256095ac560",
   "metadata": {},
   "source": [
    "Calling `head()` provides a useful quick look at the top of the dataset. Calling `dim()` helps us make sure we have the right dataset loaded up in the correct way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec424212-8c95-44f2-94ec-d3d3841eae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(pheights)\n",
    "dim(pheights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa4cba-006a-448b-9d01-6461cf2c3b21",
   "metadata": {},
   "source": [
    "Calculating the Pearson correlation cleanly seems to require passing a few options. `method = \"pearson\"` appears to be redundant here, but I'll include it anyway. __R__ and other statistical programs tend to get finicky about missing observations, and `use = \"complete.obs\"` seems to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be791854-d6dc-4439-9b1a-3852ee354124",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = cor(pheights$father, pheights$son,\n",
    "        method = \"pearson\",\n",
    "        use = \"complete.obs\"\n",
    "       )\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93872f8-153a-484c-bef4-1a16102c0747",
   "metadata": {},
   "source": [
    "As we discussed in the notebook for Class 06, it turns out that we can also use `lm()` to estimate the blue line using <b>ordinary least squares</b>, which we will return to later in COMPSS 202.\n",
    "\n",
    "The syntax of `lm()` is as follows, where the funny part with the tilde (~) is the estimation equation, with a tilde instead of an equals sign and no coefficients formally listed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaaad3b-ded3-46ed-8424-07a1f43a44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 <- lm(son ~ father,\n",
    "          data = pheights)\n",
    "summary(reg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2d4b6-69ae-4086-9737-9877fb4b7cee",
   "metadata": {},
   "source": [
    "Notice how `lm()` produces a `Multiple R-squared:` toward the bottom of the summary window. For a bivariate regression with one $Y$ regressed on one $X$, this is simply the square of the Pearson correlation, $r$. To wit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c5561-a1e1-4bc5-9dfb-b1c1b4fee4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f91a4-c592-4583-ac15-1a804d3542d6",
   "metadata": {},
   "source": [
    "<h2>2. Some remarks about $R^2$</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce934d-3686-41a2-8300-1ab43e5c39e7",
   "metadata": {},
   "source": [
    "<h3>2.1. What the $R^2$ is</h3>\n",
    "As shown in the Class 08 slides, the $R^2$ <b>measures the total amount of variation in $Y$ that the model can explain</b> with a constant term and with the variance in $X$. How can we show this? What's the total variance in $Y$?\n",
    "$$\n",
    "Var(Y) = \\frac{1}{n} \\sum_n (Y - \\bar{Y})^2\n",
    "$$\n",
    "And the math in the slides shows this:\n",
    "$$\n",
    "R^2 = \\frac{\\sum_n (\\hat{Y} - \\bar{Y})^2}\n",
    "{\\sum_n (Y - \\bar{Y})^2}\n",
    "$$\n",
    "The denominator is $n$ times the variance in $Y$. The numerator is $n$ times the variance in the OLS prediction $\\hat{Y}$. The $n$'s cancel, and the formula is thus shorthand for the ratio of the total variance in the OLS prediction as a share of the total variance in the outcome variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027f394-2604-446b-868e-38374f5429fb",
   "metadata": {},
   "source": [
    "<h3>2.2. What the $R^2$ is NOT</h3>\n",
    "\n",
    "We currently have <b>nothing to say about the \"significance\" of $X$</b> or anything else in predicting $Y$. All the $R^2$ tells us about is the fit of the model.\n",
    "\n",
    "Because there are several moving pieces here, the model fit is really all we can discuss at this stage, even though we would probably like to say something about the relationship between father's height $X$ and son's height $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05568a-9e2f-480f-8188-09d2783c2bc6",
   "metadata": {},
   "source": [
    "<h3>2.3. Is $R^2 = 0.25$ too small, too big, or just right?</h3>\n",
    "\n",
    "Goldilocks would clearly choose to run Baby Bear's model, which fit just right!\n",
    "\n",
    "Model fit is a funny thing in statistics generally, and I think it's especially quirky in social science, where usually we care a lot more about the statistical significance and causality of a treatment effect on an outcome, and we care less about the model fit per se. A treatment effect is a parameter like $\\beta$, if the $X$ variable represents something like receiving a medical treatment, taking a drug, receiving a cash transfer, or winning a charter school lottery.\n",
    "\n",
    "The outcome variables ($Y$) that we usually care about in social science are things like years of schooling or diplomas attained, earnings, self-reported happiness, good health, and so on. Each of these $Y$'s are themselves shifted by many other variables that are often outside the reach of policy levers, like our childhood conditions, our parents, our genes, systemic racism and discrimination, and so on. Thus it would be natural to find $R^2$'s that are pretty low, because our outcome variables are shifted by many other sources of variation in addition, hopefully, to the policy variable of interest.\n",
    "\n",
    "An $R^2 = 0.25$ in some circles might cause gasps of joy, while in other circles may be cause for concern. It depends a lot on the objective of the modeling. If it's critical to predict $Y$ with low error, then $0.25$ isn't great. If instead we care about the ability to <b>reject the null hypothesis</b> that $\\beta = 0$, then ...\n",
    "\n",
    "<div style=\"text-align: right\">... stay tuned for the second half of COMPSS 202!</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af27448d-dad8-4d23-b007-abdebebed223",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a055a06-6358-4323-887f-15de34df236e",
   "metadata": {},
   "source": [
    "<h2>3. Regression to the mean in flights data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b04e6f-dad6-4a99-b592-6c95a162246b",
   "metadata": {},
   "source": [
    "As the slides lay out, the <b>regression fallacy</b> is the mistaken belief that something other than \"regression to the mean\" is driving the likelihood of average results after either above-average or below-average results. It's the false belief in a causal meaning behind the statistical likelihood of mediocre peformance following either excellent or poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaaff99-7d55-476b-b3f4-9c423fbb498b",
   "metadata": {},
   "source": [
    "The classic paper in this field is [Tversky and Kahneman (1974)](https://www-jstor-org.libproxy.berkeley.edu/stable/1738360), who examined flight training data in Israel and found:\n",
    "* Strong regression to the mean in the quality of a pilot's successive flights\n",
    "* Strong beliefs that praise was harmful and criticism was valuable\n",
    "\n",
    "The two of these appearing together is not an accident; it is the regression fallacy in operation. Pilots who really \"stuck the landing\" (i.e., did it very well, above average) might receive praise. Pilots who were waved off might receive criticism. If regression to the mean is strong in flight training, pilots who did very well and incidentally received praise would likely do much more average on the next flight, regressing to the mean. Pilots who did very poorly and received criticism would likely do much more average on the next flight, regressing to the mean.\n",
    "\n",
    "There could easily be no true causal effect of praise or criticism in such a context, but they would be correlated because of the regression effect, and observers would and did conclude that praise was harmful and criticism was good. This formed a key part of Daniel Kahneman's Nobel oeuvre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430a2fd-fe26-46a3-b3cc-d5405de1ac28",
   "metadata": {},
   "source": [
    "<h3>3.1. Flights data from Dorsey-Palmateer and Smith (2006)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed281b-0add-4a3b-a2c3-1bbaf2c11f70",
   "metadata": {},
   "source": [
    "[Dorsey-Palmateer and Smith (2006)](https://economics-files.pomona.edu/garysmith/papers/flightTests.pdf) find strong regression to the mean in U.S. Navy flight training data, which they summarize in their Table 3, reprinted below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d349c8a8-9bda-4499-846f-413aa6184d08",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ryanedw/COMPSS-202-SU24/main/Images/dorsey-palmateer-smith-table3.png\" width=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22c4bc-7c5b-4d88-a1b7-120db3c11390",
   "metadata": {},
   "source": [
    "These are subjective scores with qualitative labels that are described in the paper and in the slides for Class 08. The important thing is that 1 is the worst and 5 is the best. There are clear modes at score 3.\n",
    "\n",
    "I created a dataset with 1,711 observations of two variables: `previous` and `current` contained in the Google Sheets file below. As shown in the slides for Class 08, I had also years ago created two perturbed versions of these data `pp` and `cp` using the uniform random number generator in Microsoft Excel and simulating two additive errors distributed $N(0,0.5^2)$, i.e. drawn from a normal distribution with mean $0$ and standard deviation $0.5$.\n",
    "\n",
    "Here is a direct link to the Google Sheets file loaded in the cell below: [flights.sheets](https://docs.google.com/spreadsheets/d/1wkZQc8PWq-J0NS8-oFAHGaWqctFTnB_jntgn6K8M-XA/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f911b7d-f201-4b87-84c9-57ac5519e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1wkZQc8PWq-J0NS8-oFAHGaWqctFTnB_jntgn6K8M-XA/edit?usp=sharing\"\n",
    "\n",
    "flights <- read_sheet(sheet_url,\n",
    "                      range = \"A1:E1712\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a3013-bb9d-4b0f-acd4-9fd199903651",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(flights)\n",
    "mean(flights$previous)\n",
    "mean(flights$current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeec986-a610-4d4d-b72a-1cdcb32186f1",
   "metadata": {},
   "source": [
    "Below is a look at the unadjusted data, which produce a pretty indecipherable scatterplot because are discrete in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7aead3-c507-45de-9ede-54c418939f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(flights$previous, flights$current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a4c04-1752-4600-b416-1c9eaa38e685",
   "metadata": {},
   "source": [
    "<h3>3.2. Visualizations like that are unfortunately common</h3>\n",
    "\n",
    "In social science, it is common for outcome and treatment variables to be lumpy and discrete rather than continuous. The original dataset of heights collected by Pearson and Galton, for example, was much more like this in nature than it was like the training version we have been examining. In cases like these, scatterplots might just create more confusion rather than help us visualize relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b062e1d-13af-4027-ad25-a653e99d6964",
   "metadata": {},
   "source": [
    "It turns out that __R__ has a built-in function `jitter()`, [documented here](https://search.r-project.org/R/refmans/base/html/jitter.html) which can inject randomness into observations. Below is some code that does it, with the `amount` parameter set to 1. It's good form to `set.seed()` to something, perhaps today's date, so that you can reproduce what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5540b6-7e8a-4bff-965e-d53408b69670",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(20240612)\n",
    "\n",
    "plot(jitter(flights$previous, amount = 1), \n",
    "     jitter(flights$current, amount = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f6917-4e91-4b1a-ad7c-55ece5b93356",
   "metadata": {},
   "source": [
    "The documentation reports that `jitter()` is using uniformly distributed random variables. I think normally distributed random variables are likely to look better. Here is some code that resets the seed and calls `rnorm()` with mean 0 and variance equal to `randvar`, then it adds those random shocks onto the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af96a18-2fe0-4bbf-b3f2-a41af4e9d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(20240612)\n",
    "randvar = 0.36\n",
    "flights$rand1 = rnorm(nrow(flights),0,randvar)\n",
    "flights$rand2 = rnorm(nrow(flights),0,randvar)\n",
    "\n",
    "flights$previousr = flights$previous + flights$rand1\n",
    "flights$currentr  = flights$current + flights$rand2\n",
    "\n",
    "# Uncomment these as needed for diagnostic purposes \n",
    "#head(flights)\n",
    "#sd(flights$rand1)\n",
    "#sd(flights$rand2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca868284-0a10-4d6e-9094-82892bf54c08",
   "metadata": {},
   "source": [
    "Let's look at the visualization with my normally distributed shocks. This should look more like the image in the slides, which is what I originally did with Excel some years ago. (Those data are included as `pp` and `cp` if you're interested in examining them here.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3be987-76f3-4f80-8573-228647e1cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(flights$previousr, flights$currentr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af55c7-9b47-4dc7-94d2-a3d7e1416922",
   "metadata": {},
   "source": [
    "Definitely better, but of course a challenge is that we're trying to reshape something that is basically a nebulous cloud, not an obvious football.\n",
    "\n",
    "Here is the least squares regression run on these data that I perturbed by hand. We are estimating this equation:\n",
    "\n",
    "$$\n",
    "current_i = \\alpha + \\beta \\ previous_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where $previous_i$ is the quality of the pilot's previous flight and $current_i$ is the quality of the current flight. As usual, $\\epsilon_i$ is a white-noise error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e4b12-74de-4f5c-8d40-24903f7baa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_flightsr <- lm(currentr ~ previousr,\n",
    "                   data = flights\n",
    "                   )\n",
    "summary(reg_flightsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9069da68-ed2b-4eff-b5d1-7b60d3ac003e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a862ac-7229-4832-bc3d-5288736c6c9c",
   "metadata": {},
   "source": [
    "In the randomly perturbed data, we see estimates of $\\hat{\\alpha} = 2.2$ and $\\hat{\\beta} = 0.17$. \n",
    "\n",
    "And now for comparison, here is `lm()` run with the uncorrected data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885e934-3a2e-4c14-9a90-3ff3057ddc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_flights <- lm(current ~ previous,\n",
    "                  data = flights\n",
    "                  )\n",
    "summary(reg_flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb4cd6-c477-42a1-8ff3-d8639ef25ff9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dad485-93f6-4685-a1a2-48ecc747b692",
   "metadata": {},
   "source": [
    "In the actual data, $\\hat{\\beta} = 0.21$, which is larger than what we see in the randomly perturbed data. This happens because we have injected classical <i>measurement error</i> into $X$ as well as $Y$. Measurement error in $Y$ can be modeled as part of the white-noise term $\\epsilon$, but measurement error in $X$ leads to <i>attenuation</i> of regression coefficients: they become smaller in magnitude. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261750b-2150-47f7-8ca3-0c90c46d7566",
   "metadata": {},
   "source": [
    "<h3>3.3. Bottom line: strong regression to the mean</h3>\n",
    "\n",
    "A main punchline here is that in U.S. Navy data, there is strong regression to the mean. It is true that $\\hat{\\beta} = 0.2$ or so, and as we will see in the second half of COMPSS 202, that coefficient is statistically significant and thus we can reject the null hypothesis that $\\beta = 0$. But $\\beta = 0.2$ is small enough to mean that a pilot who scores $previous = X = 4$ is likely to score \n",
    "\n",
    "$$\n",
    "current = \\hat{Y} = \\hat{\\alpha} + \\hat{\\beta} \\times 4 = 2 + 0.2 \\times 4 = 2 + 0.8 = 2.8\n",
    "$$ \n",
    "\n",
    "on the next round. That's pretty close to the average, $2.6$.\n",
    "\n",
    "Under conditions such as these, it seems likely a casual observer would mistake strong regressin to the mean with purported effects of praising or criticizing, even if those effects did not exist. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f607970b-66c2-4914-91e8-0ef0e356ae43",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <span style=\"font-family:Papyrus; \">And they lived happily ever after. The End.</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5e11e-5830-43d9-8e14-7a2558058fdb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
