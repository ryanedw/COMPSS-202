{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4943e00-491f-41d4-af95-91fd1238f12d",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ryanedw/COMPSS-202/main/Images/UCB-macss.jpg\" width=\"120\" align=\"right\"/>\n",
    "<h1>COMPSS 202 Class 07</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cfe46-7f35-4fcf-88ba-49f79a894527",
   "metadata": {},
   "source": [
    "<h2>Regression Diagnostics</h2>\n",
    "\n",
    "Inspired by [SticiGui Chapter 10](https://www.stat.berkeley.edu/~stark/SticiGui/Text/regressionDiagnostics.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77f72c-9bf6-4808-856d-7779e492179a",
   "metadata": {},
   "source": [
    "<h3>Learning objectives:</h3>\n",
    "\n",
    "1. The regression line $Y = \\alpha + \\beta \\ X + \\epsilon$ has a slope $\\beta$, a constant term or “intercept” $\\alpha$, and an error $\\epsilon$\n",
    "2. Estimates of these are sometimes written $\\hat{\\beta}$ and $\\hat{\\alpha}$\n",
    "3. Once we know $\\hat{\\beta} = r \\times SD(Y)/SD(X)$, we can find $\\hat{\\alpha}$\n",
    "4. With$\\hat{\\beta}$ and $\\hat{\\alpha}$, we can predict $\\hat{Y}$ for any $X$\n",
    "5. But $\\hat{Y}$ will differ from $Y$ by the error, $\\epsilon$, and $\\epsilon$ can be big\n",
    "6. If our model is specified well, $\\epsilon$ will have mean zero and will jump around randomly. If it doesn’t, then we’re in trouble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66ba97-e239-451a-b4cd-60a2606a04b9",
   "metadata": {},
   "source": [
    "To begin, please run the cells below to load up the libraries necessary to access data in Google Sheets. Best practices include running the cells in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635104b1-d28e-480d-aadf-42c62360f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"googlesheets4\")\n",
    "library(googlesheets4)\n",
    "gs4_deauth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0097a45-8cc5-42a7-987a-6fb0c34321e5",
   "metadata": {},
   "source": [
    "<h2>1. Review of earlier results with the Pearson heights data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccedfdd-5a84-4314-a8d5-9a43043a6bda",
   "metadata": {},
   "source": [
    "Here again are 1,078 observations of \"fathers\" and \"sons\" from a well-known training dataset based on the historical work of [Karl Pearson](https://en.wikipedia.org/wiki/Karl_Pearson). Please see the Class 03 notebook for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5429b-3119-4bc7-81f2-22f113bcfc61",
   "metadata": {},
   "source": [
    "Here is a direct link to the Google Sheets file loaded in the cell below: [Pearson height data.sheets](https://docs.google.com/spreadsheets/d/1TZhFGjT-uXd9ScucSYkT0MNARNDMCRCbAQgx4jac-X8/edit?usp=drive_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881dd2a-c149-45ab-8cb2-268fc983548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1TZhFGjT-uXd9ScucSYkT0MNARNDMCRCbAQgx4jac-X8/edit?usp=drive_link\"\n",
    "\n",
    "pheights <- read_sheet(sheet_url,\n",
    "                       range = \"B13:D1091\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344247a-9db0-48b0-8f00-d256095ac560",
   "metadata": {},
   "source": [
    "Calling `head()` provides a useful quick look at the top of the dataset. Calling `dim()` helps us make sure we have the right dataset loaded up in the correct way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec424212-8c95-44f2-94ec-d3d3841eae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(pheights)\n",
    "dim(pheights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa4cba-006a-448b-9d01-6461cf2c3b21",
   "metadata": {},
   "source": [
    "Calculating the Pearson correlation cleanly seems to require passing a few options. `method = \"pearson\"` appears to be redundant here, but I'll include it anyway. __R__ and other statistical programs tend to get finicky about missing observations, and `use = \"complete.obs\"` seems to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be791854-d6dc-4439-9b1a-3852ee354124",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = cor(pheights$father, pheights$son,\n",
    "        method = \"pearson\",\n",
    "        use = \"complete.obs\"\n",
    "       )\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a038e2-5a4f-487a-a2dd-46105fb51a9a",
   "metadata": {},
   "source": [
    "Let's also calculate the standard deviations of $Y$ and $X$. First, let's calculate the sample size $n$, with `nrow()`, and then we'll use `sd()` and apply the sample size correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0968e-7c5f-474f-83bd-fdb4e333a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nrow(pheights)\n",
    "n\n",
    "\n",
    "sdY = sd(pheights$son) * sqrt( (n-1)/n )\n",
    "sdY\n",
    "\n",
    "sdX = sd(pheights$father) * sqrt( (n-1)/n )\n",
    "sdX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a4e6c-845e-475e-a18d-f2b86eae2347",
   "metadata": {},
   "source": [
    "The slope of the $SD$ line is just the ratio of $SD(Y)$ to $SD(X)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a012eb-0913-4534-9382-9c2c589af4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdlslope = sdY/sdX\n",
    "sdlslope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171b6da-f419-41dd-839a-37b22583582b",
   "metadata": {},
   "source": [
    "The $SD$ line passes through the point of averages. Here are the averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22197d95-dfc0-4034-b0a9-1d3f5cb97a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanY = mean(pheights$son)\n",
    "meanY\n",
    "\n",
    "meanX = mean(pheights$father)\n",
    "meanX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237c791-6e0f-4e36-b598-6cef38881498",
   "metadata": {},
   "source": [
    "And now here's a trick to find the intercept term in the $SD$ line. We know it runs through $\\bar{X},\\bar{Y}$ and we know its slope, $b = SD(Y)/SD(X)$. Then:\n",
    "\n",
    "$$\n",
    "\\bar{Y} = a + b \\ \\bar{X}\n",
    "$$\n",
    "$$\n",
    "a = \\bar{Y} - b \\ \\bar{X}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cae560-882d-4cf9-acdd-f128e340a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdlint = meanY - sdlslope * meanX\n",
    "sdlint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a2bbe-8cbc-4228-8853-83af86b0b84c",
   "metadata": {},
   "source": [
    "Consider this adjustment to the slope of the $SD$ line, $b$:\n",
    "\n",
    "$$\n",
    "\\beta = r \\times b = r \\times \\frac{SD(Y)}{SD(X)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8aaed-fd50-47a3-a94d-52da02db742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "betacoef = r * sdlslope\n",
    "betacoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fcc23-a919-4bd5-b676-1a563ddc0286",
   "metadata": {},
   "source": [
    "This $\\beta$ is the least squares slope coefficient, and it is also equal to the ratio of the covariance of $X$ and $Y$ to the variance of $X$:\n",
    "\n",
    "$$\n",
    "\\beta = \\frac{Cov(X,Y)}{Var(X)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d9997-2545-49fe-a9f8-0ed6170aa7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "betacoef = cov(pheights$father,pheights$son)/var(pheights$father)\n",
    "betacoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a3d0e-2f1c-49dc-a6d2-f8fa24ae71b5",
   "metadata": {},
   "source": [
    "As before, we can find the intercept $\\alpha$ using our knowledge of the slope and the point of averages:\n",
    "\n",
    "$$\n",
    "\\bar{Y} = \\alpha + \\beta \\ \\bar{X}\n",
    "$$\n",
    "$$\n",
    "\\alpha = \\bar{Y} - \\beta \\ \\bar{X}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccd54e-ab11-49d1-b017-fb9b07f6283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphacoef = meanY - betacoef * meanX\n",
    "alphacoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ddab6-f010-4ced-ad1d-10eb0899087c",
   "metadata": {},
   "source": [
    "Finally, here is a scatterplot, now with the $SD$ line superimposed in red and the linear regression line superimposed in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd0f32-f90d-4f67-bf64-603fa7e7cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pheights$father, pheights$son,\n",
    "     main = \"Pearson height dataset n = 1,078\",\n",
    "     xlab = \"Height of the father in inches\",\n",
    "     ylab = \"Height of the son in inches\")\n",
    "lines(c(60, 75), \n",
    "      c(sdlint + sdlslope*60, sdlint + sdlslope*75),\n",
    "      col = \"red\",\n",
    "      lwd = 2\n",
    "     )\n",
    "lines(c(60, 75), \n",
    "      c(alphacoef + betacoef*60, alphacoef + betacoef*75),\n",
    "      col = \"blue\",\n",
    "      lwd = 2\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c69e306-81ef-4935-aa63-2534a3127148",
   "metadata": {},
   "source": [
    "As we discussed in the notebook for Class 06, it turns out that we can also use `lm()` to estimate the blue line using <b>ordinary least squares</b>, which we will return to later in COMPSS 202.\n",
    "\n",
    "The syntax of `lm()` is as follows, where the funny part with the tilde (~) is the estimation equation, with a tilde instead of an equals sign and no coefficients formally listed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da7388-e483-4a0e-b3e9-3cceb2d99beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 <- lm(son ~ father,\n",
    "          data = pheights)\n",
    "summary(reg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d50326d-cec8-4a7c-a369-dab40f6aef97",
   "metadata": {},
   "source": [
    "In the output here, the `Estimate` for `(Intercept)` is the constant term, $\\alpha$, and the `Estimate` for `father` is $\\beta$, the ordinary least squares regression coefficient.\n",
    "\n",
    "Later in the course we will discuss what the `Std. Error` (standard error) and other columns mean. For now: the similarity between \"standard deviation\" and \"standard error\" is no accident."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fcc75e-2b93-45b0-be33-23a047bd014c",
   "metadata": {},
   "source": [
    "<h2>2. Predictions and errors</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595134e-ee7d-4ec3-a7ce-66362fbe5bc3",
   "metadata": {},
   "source": [
    "When our ordinary least squares model is simple, with one $Y$ and only one $X$, our estimates $\\hat{\\beta}$ and $\\hat{\\alpha}$ based on the Pearson correlation or the covariance are also simple. We have:\n",
    "\n",
    "$$\n",
    "Y = \\alpha + \\beta \\ X + \\epsilon\n",
    "$$\n",
    "and our estimates equation is:\n",
    "$$\n",
    "\\hat{Y} = \\hat{\\alpha} + \\hat{\\beta} \\ X\n",
    "$$\n",
    "because the average of the $\\epsilon$'s equals zero. With these specific data, we have:\n",
    "$$\n",
    "\\hat{Y} = 33.9 + 0.514 \\ X\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c880f8ef-0ea0-40b2-bedb-ee87379ebfcb",
   "metadata": {},
   "source": [
    "Suppose we look at the prediction of son's height $\\hat{Y}$ when father's height $X = 70$ inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf2e96-55da-4adf-a107-0d8c76e4cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "son_of_70 = alphacoef + betacoef * 70\n",
    "son_of_70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd722fc-e14e-47b9-85f0-a7db5a7a486c",
   "metadata": {},
   "source": [
    "Visually, this occurs where a vertical line at $X = 70$ intersects the blue regression line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f97f0-99b5-4ca8-969c-c4621cd0ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pheights$father, pheights$son,\n",
    "     main = \"Pearson height dataset n = 1,078\",\n",
    "     xlab = \"Height of the father in inches\",\n",
    "     ylab = \"Height of the son in inches\")\n",
    "lines(c(60, 75), \n",
    "      c(alphacoef + betacoef*60, alphacoef + betacoef*75),\n",
    "      col = \"blue\",\n",
    "      lwd = 2\n",
    "     )\n",
    "abline(v = 70, \n",
    "       col = \"red\",\n",
    "       lwd = 2\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93872f8-153a-484c-bef4-1a16102c0747",
   "metadata": {},
   "source": [
    "Does a prediction of son's height equal to $69.9$ given a father's height of $70$ seem small? Or about right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfce75b-e778-4737-8328-386cc8478458",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e233da-ad9e-44a7-a241-4a9fdd2feb52",
   "metadata": {},
   "source": [
    "Some of the deep insights that emerge are that linear regression\n",
    "* Is a very good model for predicting $Y$ given an $X$ (and maybe a $Z$ and more, stay tuned)\n",
    "* Imposes regression to the mean; an $X$ with a big deviation from the mean is likely to give us a $Y$ with a much smaller deviation from its mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a73e0ed-ce90-4d75-99ae-91f38df8945f",
   "metadata": {},
   "source": [
    "Error terms can be calculated by hand, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d140d-1da0-4479-ab78-ad5202240f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheights$errors = pheights$son - (alphacoef + betacoef * pheights$father)\n",
    "hist(pheights$errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c906566-b8cc-44b5-b288-a89493bb9da8",
   "metadata": {},
   "source": [
    "Or we can recover them from the `lm()` object that we created earlier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69cf60-2cd5-4eb9-a5d1-2d38acb8458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(reg1$residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389c2f2-8ddd-47ec-99df-f5a732ae4327",
   "metadata": {},
   "source": [
    "A very good thing to do is examine how the residuals behave across $X$. For that, a scatterplot is most useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1478e-d7fd-4bcd-b9d4-db8c7c6735a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pheights$father, reg1$residuals,\n",
    "     main = \"Residuals from the regression\",\n",
    "     xlab = \"Height of father, X\",\n",
    "     ylab = \"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2d4b6-69ae-4086-9737-9877fb4b7cee",
   "metadata": {},
   "source": [
    "These are good residuals. They bounce randomly all over the place. They do not follow any obvious pattern across $X$. Good stuff. Bad residuals are anything other than the white noise kind of thing shown here. If the residuals are predictable, that's bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f607970b-66c2-4914-91e8-0ef0e356ae43",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <span style=\"font-family:Papyrus; \">And they lived happily ever after. The End.</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5e11e-5830-43d9-8e14-7a2558058fdb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
